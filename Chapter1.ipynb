{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1286a1d",
   "metadata": {},
   "source": [
    "## Chaper 1: Pay Attention to LLMs\n",
    "\n",
    "### Spoilers\n",
    "\n",
    "In this chapter, we’ll:\n",
    "\n",
    "- Briefly discuss the history of language models\n",
    "- Understand the basic elements of the Transformer architecture and the attention mechanism\n",
    "- Understand the different types of fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd32eb",
   "metadata": {},
   "source": [
    "### Transformers\n",
    "\n",
    "![](https://github.com/dvgodoy/FineTuningLLMs/blob/master/images/ch1/stacked_layers.png)\n",
    "<center>Figure 1.1 - Transformer’s stacked \"layers\"</center>\n",
    "\n",
    "![](https://github.com/dvgodoy/FineTuningLLMs/blob/master/images/ch1/full_transformer.png)\n",
    "<center>Figure 1.2 - Transformer architecture in detail</center>\n",
    "\n",
    "![](https://github.com/dvgodoy/FineTuningLLMs/blob/master/images/ch1/bert_embeddings.png)\n",
    "<center>Figure 1.3 - Contextual word embeddings from BERT</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c552996",
   "metadata": {},
   "source": [
    "### Attention Is All You Need\n",
    "\n",
    "$$\n",
    "\\Large\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "<center>Equation 1.1 - Attention formula</center>\n",
    "\n",
    "![](https://github.com/dvgodoy/FineTuningLLMs/blob/master/images/ch1/translation_att.png)\n",
    "<center>Figure 1.4 - Attention scores</center>\n",
    "\n",
    "![](https://github.com/dvgodoy/FineTuningLLMs/blob/master/images/ch1/multiple_keys_context.png)\n",
    "<center>Figure 1.5 - Querying two-dimensional keys</center>\n",
    "\n",
    "$$\n",
    "\\Large\n",
    "\\text{cos}\\theta = ||Q|| ||K|| = Q \\cdot K\n",
    "$$\n",
    "<center>Equation 1.2 - Cosine similarity, norms, and the dot product</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fb7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "repo_id = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "torch.manual_seed(13)\n",
    "# Made-up embedding and projection layers\n",
    "d_model = 1024\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "linear_query = nn.Linear(d_model, d_model)\n",
    "linear_key = nn.Linear(d_model, d_model)\n",
    "linear_value = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af735141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3387,   263, 20254, 10541]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Just a dummy sentence'\n",
    "input_ids = tokenizer(sentence, return_tensors='pt')['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b190fc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding_layer(input_ids)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794a0b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Projections\n",
    "proj_key = linear_key(embeddings)\n",
    "proj_value = linear_value(embeddings)\n",
    "proj_query = linear_query(embeddings)\n",
    "# Attention scores\n",
    "dot_products = torch.matmul(proj_query, proj_key.transpose(-2, -1))\n",
    "scores = F.softmax(dot_products / np.sqrt(d_model), dim=-1)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0269fc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.matmul(scores, proj_value)\n",
    "context.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
